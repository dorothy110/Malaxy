{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfcIA0PPvJd1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.core.api import notnull\n",
        "import os\n",
        "import re\n",
        "import csv \n",
        "import json\n",
        "import glob\n",
        "from google.colab import drive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ePslXgc4ULXv"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMicj9uHUSdk",
        "outputId": "9b29245f-b7fa-4b77-c882-173ed6755b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\"\"\" using google.colab to connect the raw data file.\n",
        "    E.g., \"/content/drive/MyDrive/Malaxy.\n",
        "\n",
        "    Parameters:\n",
        "    folderName (str): The raw data file name like course,instructor,etc.\n",
        "    \n",
        "    Returns:\n",
        "    RawData: dataframe for future use\n",
        "\"\"\"\n",
        "def PrepareDataset(folderName):\n",
        "    drive.mount('/content/drive')\n",
        "    workdir = '/content/drive/MyDrive/Malaxy/'+folderName\n",
        "    RawData = pd.read_excel( os.path.join( workdir, 'RawData.xlsx' ), header=0 )\n",
        "    return RawData\n",
        "\n",
        "\n",
        "\"\"\" This method is for common merging use: \n",
        "    create a list contains different dataframe\n",
        "    it will auto loop it and merge them\n",
        "\n",
        "    Parameters:\n",
        "    tablelist: a list of dataframe contains what we want to merge\n",
        "    method: left,right or inner join\n",
        "    collumnName: the connection collumn\n",
        "\n",
        "    Returns:\n",
        "    outer_merged: merged dataframe\n",
        "\"\"\"\n",
        "def merge(tablelist,method, collumnName):\n",
        "  outer_merged = tablelist[0]\n",
        "  for i in range(len(tablelist)-1):\n",
        "    if method == \"inner\":\n",
        "      outer_merged = pd.merge(outer_merged, tablelist[i+1], how=\"inner\", on=[collumnName])\n",
        "    elif method == \"left\":\n",
        "      outer_merged = pd.merge(outer_merged, tablelist[i+1], how=\"left\", on=[collumnName])\n",
        "    else:\n",
        "      outer_merged = pd.merge(outer_merged, tablelist[i+1], how=\"right\", on=[collumnName])\n",
        "  return outer_merged\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2uaDp02UthA"
      },
      "source": [
        "# 1. Cleaning Course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLc4ofphvjwI"
      },
      "outputs": [],
      "source": [
        "\"\"\" This method is design for cleaning dirty course data: \n",
        "    E.g., take out 506 in CS506 and put it in the other column alone.\n",
        "\n",
        "    Parameters:\n",
        "    RawData (str): The dataframe created\n",
        "    ColumnName1(str): original column\n",
        "    ColumnName2(str): new column \n",
        "\n",
        "    Returns:\n",
        "    RawData: dataframe \n",
        "\"\"\"\n",
        "\n",
        "def DivColumnName(RawData,ColumnName1,ColumnName2):\n",
        "    RawData[ColumnName2] = RawData[ColumnName1]\n",
        "    for i in range(len(RawData[ColumnName1])):\n",
        "        RawData[ColumnName2][i] = re.findall(r'(.*[^\\d+$])',RawData[ColumnName1][i])\n",
        "    return RawData\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PofZB8u4W0WM"
      },
      "source": [
        "# 2. Cleaning instructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25DfNp_hW_lv"
      },
      "outputs": [],
      "source": [
        "\"\"\" This method is design for cleaning dirty instructor data: \n",
        "    E.g., i have lots of instructor info from different semester\n",
        "    1. get all csv file under this folder \n",
        "    2. add semester in each file\n",
        "    3. export and replace original files\n",
        "\n",
        "    Parameters:\n",
        "    folderName (str): The raw data file name like course,instructor,etc.\n",
        "\n",
        "    Returns:\n",
        "    True if csv file with semester added successfully.\n",
        "\"\"\"\n",
        "\n",
        "def GetAllCSV(folderName):\n",
        "     workDir = '/content/drive/MyDrive/Malaxy'+ folderName\n",
        "     # create a list to get all csv files name under this folder using os\n",
        "     fileList = os.listdir(workDir)\n",
        "     # adding path to all file names\n",
        "     filePath = np.array([workDir + file for file in fileList if file.endswith('.csv')],\n",
        "                        dtype=object)\n",
        "    # and create dataframe\n",
        "     GetAllCSV = pd.DataFrame(filePath.reshape(len(filePath), 1))\n",
        "     for path in GetAllCSV[0]:\n",
        "        df = pd.read_csv(path, encoding = \"UTF-16\", sep='\\t')\n",
        "        #semester: 2022-2023 spring\n",
        "        sem_elems = path.split('/')[-1][:-4].split(' ')\n",
        "        #change it to : Spring 2022-2023\n",
        "        semester = sem_elems[1].capitalize() + ' ' + sem_elems[0]\n",
        "        df[\"SemesterName\"] = [semester]*len(df)\n",
        "        df.to_csv(path)\n",
        "        return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WPpPYjwSSTWc",
        "outputId": "1f5a242e-4d59-4592-a5fb-eb3c9c2bc1cd"
      },
      "outputs": [],
      "source": [
        "# This is for basic cleaning dirty instructor data: \n",
        "# E.g., meged data, drop duplicateds, rename Instructors' name \n",
        "# and output a cleaned Instructor table\n",
        "\n",
        "# Sometimes I used different ways of them to clean data, there is no fixed procedure\n",
        "\n",
        "\n",
        "workDir = '/content/drive/MyDrive/Malaxy/instructor'\n",
        "#merged instructor data\n",
        "Instructordata= pd.concat(map(pd.read_csv, glob.glob(os.path.join(workDir, '*.csv'))), ignore_index= True)\n",
        "Instructordata= pd.DataFrame(Instructordata,columns = [\"Instructor Name\",\"Class (Section)\",\"SemesterName\"])\n",
        "INSTRUCTORTABLE= pd.DataFrame(Instructordata,columns = [\"Instructor Name\",'ProfessorID'])\n",
        "INSTRUCTORTABLE = INSTRUCTORTABLE.drop_duplicates()\n",
        "INSTRUCTORTABLE = INSTRUCTORTABLE.reset_index(drop=True)\n",
        "#switch first and last name \n",
        "INSTRUCTORTABLE['Professor Name'] = INSTRUCTORTABLE['Instructor Name'].str.split(',').str[1] + ' ' + INSTRUCTORTABLE['Instructor Name'].str.split(',').str[0]\n",
        "INSTRUCTORTABLE = INSTRUCTORTABLE.drop(columns=['Instructor Name'])\n",
        "INSTRUCTORTABLE.to_csv( os.path.join( workDir, 'Instructordata.csv'),encoding=\"utf-8\",sep='|')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DoyCB37uputI"
      },
      "source": [
        "# 3. Cleaning Section table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW0oOm4CmC7f"
      },
      "outputs": [],
      "source": [
        "# This is for basic cleaning dirty Section data: \n",
        "# E.g., grouby data, drop duplicateds, rename Instructors' name \n",
        "# and output a cleaned Instructor table\n",
        "\n",
        "# Sometimes I used different ways of them to clean data, there is no fixed procedure\n",
        "\n",
        "#groupby semester Name and ID\n",
        "Instructordata['SemesterID']=pd.factorize(Instructordata['SemesterName',\"SemesterID\"])[0]+1\n",
        "Instructordata = Instructordata.drop(columns=[\"SemesterName\", \"SemesterID\"])\n",
        "# drop duplicate\n",
        "Instructordata.drop_duplicates().sort_values(\"Class \")\n",
        "sectiontable = Instructordata\n",
        "#cleaning class collumn\n",
        "sectiontable[\"Class\"] = sectiontable[\"Class \"].str.strip()\n",
        "sectiontable = sectiontable.drop(columns=[\"Class \"])\n",
        "sectiontable = sectiontable.drop_duplicates()\n",
        "workDir = '/content/drive/MyDrive/Malaxy/Section'\n",
        "sectiontable.to_csv( os.path.join( workDir, 'sectiontable.csv'),encoding=\"utf-8\",sep='|')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GAzVsm1jBAM0"
      },
      "source": [
        "# 4. Cleaning grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZEE0jxyNMvF8",
        "outputId": "b0d26fb9-2729-4a7b-fbba-e4618e0b04d0"
      },
      "outputs": [],
      "source": [
        "# This is for basic cleaning dirty instructor data: \n",
        "# E.g., meged data, drop duplicateds, rename Instructors' name \n",
        "# and output a cleaned Instructor table\n",
        "\n",
        "# Sometimes I used different ways of them to clean data, there is no fixed procedure\n",
        "\n",
        "#Use courselist as reference table\n",
        "workdir=\"/content/drive/MyDrive/Malaxy/course\"\n",
        "workdir2=\"/content/drive/MyDrive/Malaxy/Grade\"\n",
        "\n",
        "    #get all abbreviation of courses\n",
        "courselist = courselist.drop_duplicates()\n",
        "courselist= courselist.reset_index(drop=True)\n",
        "courselist[\"college name\"] = courselist[\"college name\"].str.strip()\n",
        "Gradedata = pd.concat(map(pd.read_csv, glob.glob(os.path.join(workdir2, '*.csv'))), ignore_index= True)\n",
        "Gradedata.rename(columns = {'Unnamed: 0.1':'college name','Unnamed: 2':'CourseTitle'},inplace = True)\n",
        "table = [Gradedata,courselist]\n",
        "mergedcollege = merge(table,\"inner\",\"college name\")\n",
        "mergedcollege.rename(columns = {'Unnamed: 1':'sectionid'},inplace = True)\n",
        "mergedcollege = mergedcollege.drop(columns=['Unnamed: 0', 'Unnamed: 3','Unnamed: 4','college name',\"sectionid\",\"CourseTitle\",])\n",
        "mergedcollege[\"CourseWithCategoryID\"] = mergedcollege[\"abbreviation\"] + \" \"+ mergedcollege[\"sectionid\"].map(str) \n",
        "mergedcollege = mergedcollege.drop(columns=[\"abbreviation\"])\n",
        "mergedcollege = mergedcollege.dropna(subset=['GPA '])\n",
        "mergedcollege.rename(columns = {'GPA ':'GPA'},inplace = True)\n",
        "mergedcollege.drop_duplicates(subset=['SemesterName','CourseWithCategoryID'],keep='first', inplace=True)\n",
        "\n",
        "    # connect table with section id\n",
        "sectionwithid = pd.read_csv( os.path.join( workdir, 'sorry.csv' ), header=0 )\n",
        "sectionwithid1 = pd.DataFrame(sectionwithid, columns = ['CourseName','SectionId'])\n",
        "sectionwithid1.rename(columns = {'CourseName':'CourseWithCategoryID'},inplace = True)\n",
        "table = [mergedcollege,sectionwithid1]\n",
        "mergedcollege = merge(table,\"left\",\"CourseWithCategoryID\")\n",
        "mergedcollege = mergedcollege.dropna(subset=['SectionId'])\n",
        "\n",
        "mergedcollege.rename(columns = {'GPA':'Gpa', 'A':'GradeCountA', 'AB':'GradeCountAb', 'B':'GradeCountB',\n",
        "                                    'BC':'GradeCountBc', 'C':'GradeCountC', 'D':'GradeCountD', \n",
        "                                    'F':'GradeCountF', 'S/SD/CR':'GradeCountSd', 'N/U/UD':'GradeCountUd',\n",
        "        'Other':'GradeCountOther', 'Total ':'GradeCountTotal', 'SemesterName':'SemesterName', \n",
        "        'CourseWithCategoryID':'CourseWithCategoryID'},inplace = True)\n",
        "\n",
        "mergedcollege.to_csv( os.path.join( workdir, 'gradd.csv'),encoding=\"utf-8\",sep='|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm11vb6SWvxZ"
      },
      "outputs": [],
      "source": [
        "#check differences\n",
        "# sorted(list(set(Gradedata[\"college name\"].to_list())))[:10]\n",
        "# sorted(list(set(courselist[\"college name\"].to_list())))[:10]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
